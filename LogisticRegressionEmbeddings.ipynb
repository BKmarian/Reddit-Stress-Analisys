{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack, csr_matrix,vstack\n",
    "import os\n",
    "import gensim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from gensim.models import KeyedVectors\n",
    "from nltk import WordNetLemmatizer, PorterStemmer, RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix,f1_score,accuracy_score\n",
    "import gensim.downloader as api\n",
    "import warnings\n",
    "from transformers import TFDistilBertModel, DistilBertTokenizerFast, DistilBertConfig, BertModel, BertTokenizer\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import transformers as ppb # pytorch transformers\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "import warnings\n",
    "\n",
    "import swifter\n",
    "import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "ceb8a1a50d95557c6c7ac9eae7c6c11596fa88a9",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# path = '/content/Insight_Stress_Analysis/data/'\n",
    "path = '../data/'\n",
    "train = pd.read_csv(path + 'dreaddit-train-processed.csv', encoding = \"ISO-8859-1\")\n",
    "test = pd.read_csv(path + 'dreaddit-test-processed.csv', encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'lex_liwc_WC', 'lex_liwc_Analytic', 'lex_liwc_Clout',\n",
      "       'lex_liwc_Authentic', 'lex_liwc_Tone', 'lex_liwc_WPS',\n",
      "       'lex_liwc_Sixltr', 'lex_liwc_Dic', 'lex_liwc_function',\n",
      "       ...\n",
      "       'lex_dal_min_pleasantness', 'lex_dal_min_activation',\n",
      "       'lex_dal_min_imagery', 'lex_dal_avg_activation', 'lex_dal_avg_imagery',\n",
      "       'lex_dal_avg_pleasantness', 'social_upvote_ratio',\n",
      "       'social_num_comments', 'syntax_fk_grade', 'sentiment'],\n",
      "      dtype='object', length=107)\n"
     ]
    }
   ],
   "source": [
    "features_train = train.drop(['subreddit','post_id','sentence_range','text','id','label','confidence','social_timestamp','social_karma','syntax_ari','processed_text'], 1)\n",
    "features_test = test.drop(['subreddit','post_id','sentence_range','text','id','label','confidence','social_timestamp','social_karma','syntax_ari','processed_text'], 1)\n",
    "\n",
    "print(features_train.columns)\n",
    "features_len = len(features_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def flatten_lists(lst):\n",
    "    \"\"\"Remove nested lists.\"\"\"\n",
    "    return [item for sublist in lst for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "9262693cc3bf753ee0cf9c8b6dbd73afa42b390d",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "w2v = gensim.models.Word2Vec(list(train[\"processed_text\"]), window=10, min_count=2,\n",
    "                                vector_size=300,\n",
    "                                workers=10,\n",
    "                                epochs=100)\n",
    "glove = KeyedVectors.load_word2vec_format('../GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "8a928ea00a08dbd276e653dd2578b6b03c3ff91b",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def document_vector(doc):\n",
    "    \"\"\"Create document vectors by averaging word vectors. Remove out-of-vocabulary words.\"\"\"\n",
    "    doc = [word for word in doc if word in list(w2v.wv.index_to_key)]\n",
    "    return np.mean(w2v.wv[doc], axis=0)\n",
    "\n",
    "\n",
    "def document_vector_glove(doc):\n",
    "    \"\"\"Create document vectors by averaging word vectors. Remove out-of-vocabulary words.\"\"\"\n",
    "    word_vecs = list()\n",
    "    for word in doc:\n",
    "        try:\n",
    "            word_vec = glove.word_vec(word)\n",
    "        except KeyError:\n",
    "            word_vec = np.zeros([300], dtype=np.float32)\n",
    "        word_vecs.append(word_vec)\n",
    "    return np.mean(word_vecs, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: Domain Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "b8d1e09c13271f9f2386f82170e88da153383cc9",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "train['doc_vector'] = train[\"processed_text\"].apply(document_vector)\n",
    "test['doc_vector'] = test[\"processed_text\"].apply(document_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_f = np.stack(train['doc_vector'])\n",
    "test_f = np.stack(test['doc_vector'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2838, 300)\n",
      "(2838, 107)\n"
     ]
    }
   ],
   "source": [
    "print(train_f.shape)\n",
    "print(features_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "## Append Features\n",
    "train_f = np.concatenate((features_train, train_f), axis=1)\n",
    "test_f = np.concatenate((features_test, test_f), axis=1)\n",
    "# train_f = hstack([features_train,train_f])\n",
    "# test_f = hstack([features_test,test_f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2838, 407)\n",
      "(715, 407)\n"
     ]
    }
   ],
   "source": [
    "print(train_f.shape)\n",
    "print(test_f.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "0b285a219ecf0bf0e1fbeae56aa372acca123865",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "X = list(train_f)\n",
    "y = list(train[\"label\"])\n",
    "X_test = list(test_f)\n",
    "y_test = list(test['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "6e9038cfdaac47a4f3f504892531f92f5a4d7024",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "clf = LogisticRegression(C=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "eaef3e8e4ad6a1b46e1ce6bcf605c0f399efc550",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "1a79d7fdf1fa059d40e5e85b176cdb1fc58cb0f7",
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "d1544ffc6656be3fe612c041e7ce18143269f917",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7596899224806202\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model 2: Pretrained Word2vec #TODO change with pubmed word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train['doc_vector'] = train[\"processed_text\"].apply(document_vector_glove)\n",
    "test['doc_vector'] = test[\"processed_text\"].apply(document_vector_glove)\n",
    "\n",
    "train_f = np.stack(train['doc_vector'])\n",
    "test_f = np.stack(test['doc_vector'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_f = np.concatenate((features_train, train_f), axis=1)\n",
    "test_f = np.concatenate((features_test, test_f), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X = list(train_f)\n",
    "y = list(train[\"label\"])\n",
    "X_test = list(test_f)\n",
    "y_test = list(test['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "clf = LogisticRegression(C=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.761038961038961\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model 3: Bert word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "#\n",
    "bert_model = BertModel.from_pretrained(\"bert-base-uncased\").to(\"cuda\")\n",
    "# tokenized_text = torch.tensor(tokenized_dict[\"input_ids\"])\n",
    "# with torch.no_grad():\n",
    "#   embeddings = bert_model(torch.tensor(tokenized_text.unsqueeze(0)))\n",
    "#\n",
    "# get_cls = lambda x: x[0][:, 0, :].squeeze()\n",
    "# flatten_embed = lambda x: torch.flatten(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "class BertTokenizer(object):\n",
    "\n",
    "    def __init__(self, text=[]):\n",
    "        self.text = text\n",
    "\n",
    "        self.model_class, self.tokenizer_class, self.pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')\n",
    "        # Load pretrained model/tokenizer\n",
    "        self.tokenizer = self.tokenizer_class.from_pretrained(self.pretrained_weights)\n",
    "\n",
    "        self.model = self.model_class.from_pretrained(self.pretrained_weights).to(\"cuda\")\n",
    "\n",
    "    def get(self):\n",
    "\n",
    "        df = pd.DataFrame(data={\"text\":self.text})\n",
    "        tokenized = df[\"text\"].swifter.apply((lambda x: self.tokenizer.encode(x, add_special_tokens=True)))\n",
    "\n",
    "        max_len = 256\n",
    "\n",
    "        padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])\n",
    "\n",
    "        attention_mask = np.where(padded != 0, 1, 0)\n",
    "        input_ids = torch.tensor(padded).cuda()\n",
    "        attention_mask = torch.tensor(attention_mask).cuda()\n",
    "\n",
    "        with torch.no_grad(): last_hidden_states = self.model(input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        features = last_hidden_states[0][:, 0, :].numpy()\n",
    "\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_2652\\1159572738.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcuda\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mempty_cache\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m \u001B[0m_instance\u001B[0m \u001B[1;33m=\u001B[0m\u001B[0mBertTokenizer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtext\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtrain\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"processed_text\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      4\u001B[0m \u001B[0mtokens_train\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_instance\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[0m_instance2\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mBertTokenizer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtext\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtest\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"processed_text\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_2652\\4118697527.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, text)\u001B[0m\n\u001B[0;32m      7\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmodel_class\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtokenizer_class\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpretrained_weights\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mppb\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mBertModel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mppb\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mBertTokenizer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'bert-base-uncased'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      8\u001B[0m         \u001B[1;31m# Load pretrained model/tokenizer\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 9\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtokenizer\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtokenizer_class\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfrom_pretrained\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpretrained_weights\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     10\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     11\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmodel\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmodel_class\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfrom_pretrained\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpretrained_weights\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"cuda\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\NLPproiect\\venv\\lib\\site-packages\\transformers\\tokenization_utils_base.py\u001B[0m in \u001B[0;36mfrom_pretrained\u001B[1;34m(cls, pretrained_model_name_or_path, *init_inputs, **kwargs)\u001B[0m\n\u001B[0;32m   1725\u001B[0m                         \u001B[0mlocal_files_only\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mlocal_files_only\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1726\u001B[0m                         \u001B[0muse_auth_token\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0muse_auth_token\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1727\u001B[1;33m                         \u001B[0muser_agent\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0muser_agent\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1728\u001B[0m                     )\n\u001B[0;32m   1729\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\NLPproiect\\venv\\lib\\site-packages\\transformers\\utils\\hub.py\u001B[0m in \u001B[0;36mcached_path\u001B[1;34m(url_or_filename, cache_dir, force_download, proxies, resume_download, user_agent, extract_compressed_file, force_extract, use_auth_token, local_files_only)\u001B[0m\n\u001B[0;32m    288\u001B[0m             \u001B[0muser_agent\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0muser_agent\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    289\u001B[0m             \u001B[0muse_auth_token\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0muse_auth_token\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 290\u001B[1;33m             \u001B[0mlocal_files_only\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mlocal_files_only\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    291\u001B[0m         )\n\u001B[0;32m    292\u001B[0m     \u001B[1;32melif\u001B[0m \u001B[0mos\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexists\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0murl_or_filename\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\NLPproiect\\venv\\lib\\site-packages\\transformers\\utils\\hub.py\u001B[0m in \u001B[0;36mget_from_cache\u001B[1;34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, use_auth_token, local_files_only)\u001B[0m\n\u001B[0;32m    483\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mlocal_files_only\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    484\u001B[0m         \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 485\u001B[1;33m             \u001B[0mr\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mrequests\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhead\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0murl\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mheaders\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mheaders\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mallow_redirects\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mproxies\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mproxies\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtimeout\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0metag_timeout\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    486\u001B[0m             \u001B[0m_raise_for_status\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mr\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    487\u001B[0m             \u001B[0metag\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mr\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mheaders\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"X-Linked-Etag\"\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0mr\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mheaders\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"ETag\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\NLPproiect\\venv\\lib\\site-packages\\requests\\api.py\u001B[0m in \u001B[0;36mhead\u001B[1;34m(url, **kwargs)\u001B[0m\n\u001B[0;32m    100\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    101\u001B[0m     \u001B[0mkwargs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msetdefault\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'allow_redirects'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;32mFalse\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 102\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0mrequest\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'head'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0murl\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    103\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    104\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\NLPproiect\\venv\\lib\\site-packages\\requests\\api.py\u001B[0m in \u001B[0;36mrequest\u001B[1;34m(method, url, **kwargs)\u001B[0m\n\u001B[0;32m     59\u001B[0m     \u001B[1;31m# cases, and look like a memory leak in others.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     60\u001B[0m     \u001B[1;32mwith\u001B[0m \u001B[0msessions\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mSession\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0msession\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 61\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0msession\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrequest\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmethod\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mmethod\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0murl\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0murl\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     62\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     63\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\NLPproiect\\venv\\lib\\site-packages\\requests\\sessions.py\u001B[0m in \u001B[0;36mrequest\u001B[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001B[0m\n\u001B[0;32m    527\u001B[0m         }\n\u001B[0;32m    528\u001B[0m         \u001B[0msend_kwargs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msettings\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 529\u001B[1;33m         \u001B[0mresp\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprep\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0msend_kwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    530\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    531\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mresp\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\NLPproiect\\venv\\lib\\site-packages\\requests\\sessions.py\u001B[0m in \u001B[0;36msend\u001B[1;34m(self, request, **kwargs)\u001B[0m\n\u001B[0;32m    643\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    644\u001B[0m         \u001B[1;31m# Send the request\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 645\u001B[1;33m         \u001B[0mr\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0madapter\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mrequest\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    646\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    647\u001B[0m         \u001B[1;31m# Total elapsed time of the request (approximately)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\NLPproiect\\venv\\lib\\site-packages\\requests\\adapters.py\u001B[0m in \u001B[0;36msend\u001B[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001B[0m\n\u001B[0;32m    448\u001B[0m                     \u001B[0mdecode_content\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    449\u001B[0m                     \u001B[0mretries\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmax_retries\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 450\u001B[1;33m                     \u001B[0mtimeout\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    451\u001B[0m                 )\n\u001B[0;32m    452\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\NLPproiect\\venv\\lib\\site-packages\\urllib3\\connectionpool.py\u001B[0m in \u001B[0;36murlopen\u001B[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001B[0m\n\u001B[0;32m    708\u001B[0m                 \u001B[0mbody\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mbody\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    709\u001B[0m                 \u001B[0mheaders\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mheaders\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 710\u001B[1;33m                 \u001B[0mchunked\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mchunked\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    711\u001B[0m             )\n\u001B[0;32m    712\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\NLPproiect\\venv\\lib\\site-packages\\urllib3\\connectionpool.py\u001B[0m in \u001B[0;36m_make_request\u001B[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001B[0m\n\u001B[0;32m    384\u001B[0m         \u001B[1;31m# Trigger any extra validation we need to do.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    385\u001B[0m         \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 386\u001B[1;33m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_validate_conn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mconn\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    387\u001B[0m         \u001B[1;32mexcept\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mSocketTimeout\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mBaseSSLError\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    388\u001B[0m             \u001B[1;31m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\NLPproiect\\venv\\lib\\site-packages\\urllib3\\connectionpool.py\u001B[0m in \u001B[0;36m_validate_conn\u001B[1;34m(self, conn)\u001B[0m\n\u001B[0;32m   1038\u001B[0m         \u001B[1;31m# Force connect early to allow us to validate the connection.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1039\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mgetattr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mconn\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"sock\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m  \u001B[1;31m# AppEngine might not have  `.sock`\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1040\u001B[1;33m             \u001B[0mconn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mconnect\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1041\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1042\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mconn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mis_verified\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\NLPproiect\\venv\\lib\\site-packages\\urllib3\\connection.py\u001B[0m in \u001B[0;36mconnect\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    422\u001B[0m             \u001B[0mserver_hostname\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mserver_hostname\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    423\u001B[0m             \u001B[0mssl_context\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcontext\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 424\u001B[1;33m             \u001B[0mtls_in_tls\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtls_in_tls\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    425\u001B[0m         )\n\u001B[0;32m    426\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\NLPproiect\\venv\\lib\\site-packages\\urllib3\\util\\ssl_.py\u001B[0m in \u001B[0;36mssl_wrap_socket\u001B[1;34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir, key_password, ca_cert_data, tls_in_tls)\u001B[0m\n\u001B[0;32m    448\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0msend_sni\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    449\u001B[0m         ssl_sock = _ssl_wrap_socket_impl(\n\u001B[1;32m--> 450\u001B[1;33m             \u001B[0msock\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcontext\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtls_in_tls\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mserver_hostname\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mserver_hostname\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    451\u001B[0m         )\n\u001B[0;32m    452\u001B[0m     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\NLPproiect\\venv\\lib\\site-packages\\urllib3\\util\\ssl_.py\u001B[0m in \u001B[0;36m_ssl_wrap_socket_impl\u001B[1;34m(sock, ssl_context, tls_in_tls, server_hostname)\u001B[0m\n\u001B[0;32m    491\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    492\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mserver_hostname\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 493\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mssl_context\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwrap_socket\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msock\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mserver_hostname\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mserver_hostname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    494\u001B[0m     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    495\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mssl_context\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwrap_socket\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msock\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python37_64\\lib\\ssl.py\u001B[0m in \u001B[0;36mwrap_socket\u001B[1;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001B[0m\n\u001B[0;32m    421\u001B[0m             \u001B[0mserver_hostname\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mserver_hostname\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    422\u001B[0m             \u001B[0mcontext\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 423\u001B[1;33m             \u001B[0msession\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0msession\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    424\u001B[0m         )\n\u001B[0;32m    425\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python37_64\\lib\\ssl.py\u001B[0m in \u001B[0;36m_create\u001B[1;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001B[0m\n\u001B[0;32m    868\u001B[0m                         \u001B[1;31m# non-blocking\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    869\u001B[0m                         \u001B[1;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"do_handshake_on_connect should not be specified for non-blocking sockets\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 870\u001B[1;33m                     \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdo_handshake\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    871\u001B[0m             \u001B[1;32mexcept\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mOSError\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mValueError\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    872\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mclose\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python37_64\\lib\\ssl.py\u001B[0m in \u001B[0;36mdo_handshake\u001B[1;34m(self, block)\u001B[0m\n\u001B[0;32m   1137\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mtimeout\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;36m0.0\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0mblock\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1138\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msettimeout\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1139\u001B[1;33m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_sslobj\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdo_handshake\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1140\u001B[0m         \u001B[1;32mfinally\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1141\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msettimeout\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "_instance =BertTokenizer(text=train[\"processed_text\"])\n",
    "tokens_train = _instance.get()\n",
    "_instance2 = BertTokenizer(text=test[\"processed_text\"])\n",
    "tokens_test = _instance2.get()\n",
    "\n",
    "features_tensor_train = torch.tensor(features_train)\n",
    "features_tensor_test = torch.tensor(features_test)\n",
    "\n",
    "lr_clf = LogisticRegression(C=100)\n",
    "lr_clf.fit(torch.cat(tokens_train,features_tensor_train), train[\"label\"])\n",
    "\n",
    "predicted = lr_clf.predict(torch.cat(tokens_test,features_tensor_test))\n",
    "\n",
    "print(f1_score(predicted,test[\"label\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}